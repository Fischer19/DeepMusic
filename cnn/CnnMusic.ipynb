{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "device = torch.device(2 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CnnMusic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnMusic, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 32, 3, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 128, 3, padding=2)\n",
    "        self.conv3 = nn.Conv1d(128, 64, 3, padding=2)\n",
    "        self.conv4 = nn.Conv1d(64, 64, 3, padding=2)\n",
    "        self.conv5 = nn.Conv1d(64, 64, 3, padding=2)\n",
    "        self.upsample1 = nn.ConvTranspose1d(64, 64, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv6 = nn.Conv1d(128, 64, 3, padding=2)\n",
    "        self.upsample2 = nn.ConvTranspose1d(64, 64, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv7 = nn.Conv1d(128, 128, 3, padding=2)\n",
    "        self.upsample3 = nn.ConvTranspose1d(128, 128, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv8 = nn.Conv1d(256, 128, 3, padding=2)\n",
    "        self.upsample4 = nn.ConvTranspose1d(128, 128, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv9 = nn.Conv1d(160, 40, 3, padding=2)\n",
    "        self.conv10 = nn.Conv1d(40, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=x[:,:,:-2]\n",
    "        skip1=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv2(x)\n",
    "        x=x[:,:,:-2]\n",
    "        skip2=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv3(x)\n",
    "        x=x[:,:,:-2]\n",
    "        skip3=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv4(x)\n",
    "        x=x[:,:,:-2]\n",
    "        skip4=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv5(x)\n",
    "        x=x[:,:,:-2]\n",
    "        x=self.upsample1(x)\n",
    "        x=torch.cat((x,skip4), dim=1)\n",
    "        x=self.conv6(x)\n",
    "        x=x[:,:,:-2]\n",
    "        x=self.upsample2(x)\n",
    "        #x=self.upsample2(self.conv6(x))\n",
    "        x=torch.cat((x,skip3), dim=1)\n",
    "        x=self.conv7(x)\n",
    "        x=x[:,:,:-2]\n",
    "        x=self.upsample3(x)\n",
    "        #x=self.upsample3(self.conv7(x))\n",
    "        x=torch.cat((x,skip2), dim=1)\n",
    "        x=self.conv8(x)\n",
    "        x=x[:,:,:-2]\n",
    "        x=self.upsample4(x)\n",
    "        #x=self.upsample4(self.conv8(x))\n",
    "        x=torch.cat((x,skip1), dim=1)\n",
    "        x=self.conv9(x)\n",
    "        x=x[:,:,:-2]\n",
    "        x=self.conv10(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512])\n",
      "torch.Size([1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "model=CnnMusic()\n",
    "x=torch.from_numpy(np.random.randn(1,3,512)).float()\n",
    "print(x.shape)\n",
    "y=model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373\n",
      "1373\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/yiqin/2018summer_project/data/smooth_data_long.pkl\", \"rb\") as f:\n",
    "    dic = pickle.load(f)\n",
    "    train_X = dic[\"X\"]\n",
    "    train_Y = dic[\"Y\"]\n",
    "print(len(train_X))\n",
    "print(len(train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "for i, x in enumerate(train_X):\n",
    "    temp=[]\n",
    "    temp.append(train_X[i])\n",
    "    temp.append(train_Y[i])\n",
    "    data.append(temp)\n",
    "import random\n",
    "#random.shuffle(data)\n",
    "print(len(data))\n",
    "train_data=data[:1300]\n",
    "val_data=data[1300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size=len(val_data)\n",
    "val_x=np.zeros((val_size,3,880))\n",
    "val_y=np.zeros((val_size,1,880))\n",
    "val_len=[]\n",
    "for i in range(val_size):\n",
    "    val_len.append(len(val_data[i][0]))\n",
    "    l=len(val_data[i][0])\n",
    "    for j in range(880):\n",
    "        val_x[i][0][j]=val_data[i][0][j%l][1]-val_data[i][0][j%l][0]\n",
    "        val_x[i][1][j]=val_data[i][0][j%l][2]\n",
    "        if (j%l)!=l-1:\n",
    "            val_x[i][2][j]=val_data[i][0][(j+1)%l][0]-val_data[i][0][j%l][1]\n",
    "        else:\n",
    "            val_x[i][2][j]=random.random()\n",
    "        val_y[i][0][j]=val_data[i][1][j%l]\n",
    "#print(val_x)\n",
    "#print(val_y)\n",
    "val_x=Variable(torch.from_numpy(val_x).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(prediction):\n",
    "    output=[]\n",
    "    s, _, l = prediction.shape\n",
    "    for i in range(s):\n",
    "        temp=[]\n",
    "        for j in range(l-1):\n",
    "            if j==0:\n",
    "                temp.append(0)\n",
    "                continue\n",
    "            if prediction[i][0][j]>0.5 and prediction[i][0][j]>prediction[i][0][j+1] and prediction[i][0][j]>prediction[i][0][j-1]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        output.append(temp)\n",
    "    return output\n",
    "\n",
    "def compute_acc(p, g):\n",
    "    s, _, l = p.shape\n",
    "    p=decode(p)\n",
    "    g=decode(g)\n",
    "    cor=0\n",
    "    total=0\n",
    "    for i in range(s):\n",
    "        for j in range(l-1):\n",
    "            if g[i][j] == 1: total+=1\n",
    "            if p[i][j]*g[i][j] == 1: cor+=1\n",
    "            #if p[i][j]==g[i][j]: cor+=1\n",
    "            #total+=1\n",
    "    acc=float(cor)/float(total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(index, batch_size):\n",
    "    s=index*batch_size\n",
    "    xin=np.zeros((batch_size,3,880))\n",
    "    yin=np.zeros((batch_size,1,880))\n",
    "    for i in range(batch_size):\n",
    "        l=len(train_data[s+i][0])\n",
    "        for j in range(880):\n",
    "            xin[i][0][j]=train_data[s+i][0][j%l][1]-train_data[s+i][0][j%l][0]\n",
    "            xin[i][1][j]=train_data[s+i][0][j%l][2]\n",
    "            if (j%l)!=l-1:\n",
    "                xin[i][2][j]=train_data[s+i][0][(j+1)%l][0]-train_data[s+i][0][j%l][1]\n",
    "            else:\n",
    "                xin[i][2][j]=random.random()\n",
    "            yin[i][0][j]=train_data[s+i][1][j%l]\n",
    "    return xin, yin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=CnnMusic()\n",
    "lr=1e-3\n",
    "decay=5e-8\n",
    "optimizer=optim.Adam(model.parameters(),\n",
    "                     lr=lr,\n",
    "                     weight_decay=decay)\n",
    "batch_size=100\n",
    "epochs=10000\n",
    "loss=0\n",
    "data_len=len(train_data)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(gy,y,ratio,s):\n",
    "    temp=gy.cpu().numpy()\n",
    "    mask=np.ones_like(temp)\n",
    "    mask[gy>0.99]=ratio\n",
    "    mask=torch.from_numpy(mask).to(device)\n",
    "    loss=torch.sub(gy,y)\n",
    "    loss=torch.mul(loss, loss)\n",
    "    loss=torch.mul(loss, mask)\n",
    "    loss=torch.sum(loss)\n",
    "    loss/=s\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(942.0308, device='cuda:2')\n",
      "current val acc: 0.2511456211812627\n",
      "current val acc: 0.010692464358452138\n",
      "current val acc: 0.45442973523421587\n",
      "current val acc: 0.024821792260692463\n",
      "current val acc: 0.0280040733197556\n",
      "current val acc: 0.02914969450101833\n",
      "current val acc: 0.027622199592668026\n",
      "current val acc: 0.027876782077393074\n",
      "current val acc: 0.027240325865580447\n",
      "current val acc: 0.033223014256619145\n",
      "current val acc: 0.03335030549898167\n",
      "current val acc: 0.031568228105906315\n",
      "current val acc: 0.03195010183299389\n",
      "current val acc: 0.0269857433808554\n",
      "current val acc: 0.04047861507128309\n",
      "current val acc: 0.03347759674134419\n",
      "current val acc: 0.030168024439918534\n",
      "current val acc: 0.06364562118126273\n",
      "current val acc: 0.031059063136456212\n",
      "current val acc: 0.08783095723014257\n",
      "current val acc: 0.03347759674134419\n",
      "current val acc: 0.050407331975560084\n",
      "current val acc: 0.04404276985743381\n",
      "current val acc: 0.03602342158859471\n",
      "current val acc: 0.054226069246435846\n",
      "current val acc: 0.03589613034623218\n",
      "current val acc: 0.04378818737270876\n",
      "current val acc: 0.033859470468431775\n",
      "current val acc: 0.06428207739307536\n",
      "current val acc: 0.07306517311608961\n",
      "current val acc: 0.06873727087576374\n",
      "current val acc: 0.06377291242362526\n",
      "current val acc: 0.07344704684317718\n",
      "current val acc: 0.07841140529531568\n",
      "current val acc: 0.07331975560081466\n",
      "current val acc: 0.07344704684317718\n",
      "current val acc: 0.034623217922606926\n",
      "current val acc: 0.03538696537678208\n",
      "current val acc: 0.05791751527494908\n",
      "current val acc: 0.05842668024439918\n",
      "current val acc: 0.09941446028513239\n",
      "current val acc: 0.16013238289205703\n",
      "current val acc: 0.11647148676171079\n",
      "current val acc: 0.10781568228105906\n",
      "current val acc: 0.09635947046843177\n",
      "current val acc: 0.10641547861507128\n",
      "current val acc: 0.059826883910386965\n",
      "current val acc: 0.28424134419551933\n",
      "current val acc: 0.15084012219959267\n",
      "current val acc: 0.21028513238289206\n",
      "current val acc: 0.12920061099796334\n",
      "current val acc: 0.18126272912423624\n",
      "current val acc: 0.11825356415478615\n",
      "current val acc: 0.16280549898167007\n",
      "current val acc: 0.1509674134419552\n",
      "current val acc: 0.20137474541751527\n",
      "current val acc: 0.31962830957230143\n",
      "current val acc: 0.109979633401222\n",
      "current val acc: 0.2265784114052953\n",
      "current val acc: 0.2788951120162933\n",
      "current val acc: 0.21295824847250508\n",
      "current val acc: 0.18508146639511203\n",
      "current val acc: 0.19131873727087575\n",
      "current val acc: 0.25674643584521384\n",
      "current val acc: 0.2771130346232179\n",
      "current val acc: 0.3102087576374745\n",
      "current val acc: 0.2671843177189409\n",
      "current val acc: 0.3268839103869654\n",
      "current val acc: 0.33184826883910384\n",
      "current val acc: 0.33184826883910384\n",
      "current val acc: 0.2494908350305499\n",
      "current val acc: 0.28475050916496947\n",
      "current val acc: 0.19259164969450102\n",
      "current val acc: 0.17566191446028515\n",
      "current val acc: 0.3688900203665988\n",
      "current val acc: 0.41471486761710796\n",
      "current val acc: 0.44615580448065173\n",
      "current val acc: 0.38467413441955195\n",
      "current val acc: 0.49821792260692466\n",
      "current val acc: 0.5187118126272913\n",
      "current val acc: 0.4656313645621181\n",
      "current val acc: 0.4610488798370672\n",
      "current val acc: 0.3105906313645621\n",
      "current val acc: 0.3738543788187373\n",
      "current val acc: 0.2699847250509165\n",
      "current val acc: 0.24630855397148677\n",
      "current val acc: 0.24083503054989816\n",
      "current val acc: 0.4349541751527495\n",
      "current val acc: 0.3345213849287169\n",
      "current val acc: 0.2660386965376782\n",
      "current val acc: 0.2699847250509165\n",
      "current val acc: 0.35157841140529533\n",
      "current val acc: 0.6094704684317719\n",
      "current val acc: 0.32917515274949083\n",
      "current val acc: 0.2174134419551935\n",
      "current val acc: 0.17222505091649695\n",
      "current val acc: 0.1909368635437882\n",
      "current val acc: 0.17184317718940936\n",
      "current val acc: 0.3453411405295316\n",
      "current val acc: 0.3210285132382892\n",
      "tensor(76.0130, device='cuda:2')\n",
      "current val acc: 0.269857433808554\n",
      "current val acc: 0.4240071283095723\n",
      "current val acc: 0.34585030549898166\n",
      "current val acc: 0.315173116089613\n",
      "current val acc: 0.3181008146639511\n",
      "current val acc: 0.3005346232179226\n",
      "current val acc: 0.25216395112016293\n",
      "current val acc: 0.28869653767820774\n",
      "current val acc: 0.29289714867617106\n",
      "current val acc: 0.4016038696537678\n",
      "current val acc: 0.3273930753564155\n",
      "current val acc: 0.41280549898167007\n",
      "current val acc: 0.5416242362525459\n",
      "current val acc: 0.2637474541751528\n",
      "current val acc: 0.41866089613034624\n",
      "current val acc: 0.4279531568228106\n",
      "current val acc: 0.2987525458248472\n",
      "current val acc: 0.4614307535641548\n",
      "current val acc: 0.2876782077393075\n",
      "current val acc: 0.32942973523421587\n",
      "current val acc: 0.4961812627291242\n",
      "current val acc: 0.30460794297352345\n",
      "current val acc: 0.5440427698574338\n",
      "current val acc: 0.24618126272912425\n",
      "current val acc: 0.49325356415478616\n",
      "current val acc: 0.38963849287169044\n",
      "current val acc: 0.32790224032586557\n",
      "current val acc: 0.4283350305498982\n",
      "current val acc: 0.37436354378818737\n",
      "current val acc: 0.30091649694501016\n",
      "current val acc: 0.5416242362525459\n",
      "current val acc: 0.23065173116089613\n",
      "current val acc: 0.5539714867617108\n",
      "current val acc: 0.40338594704684316\n",
      "current val acc: 0.3705448065173116\n",
      "current val acc: 0.5572810590631364\n",
      "current val acc: 0.33553971486761713\n",
      "current val acc: 0.27978615071283097\n",
      "current val acc: 0.4237525458248472\n",
      "current val acc: 0.2415987780040733\n",
      "current val acc: 0.5464613034623218\n",
      "current val acc: 0.4265529531568228\n",
      "current val acc: 0.38467413441955195\n",
      "current val acc: 0.35768839103869654\n",
      "current val acc: 0.4460285132382892\n",
      "current val acc: 0.4394093686354379\n",
      "current val acc: 0.3868380855397149\n",
      "current val acc: 0.4195519348268839\n",
      "current val acc: 0.5653004073319755\n",
      "current val acc: 0.24987270875763748\n",
      "current val acc: 0.4265529531568228\n",
      "current val acc: 0.3135183299389002\n",
      "current val acc: 0.5815936863543788\n",
      "current val acc: 0.33184826883910384\n",
      "current val acc: 0.5677189409368636\n",
      "current val acc: 0.4254073319755601\n",
      "current val acc: 0.3499236252545825\n",
      "current val acc: 0.5919042769857433\n",
      "current val acc: 0.2395621181262729\n",
      "current val acc: 0.5642820773930753\n",
      "current val acc: 0.2935336048879837\n",
      "current val acc: 0.4445010183299389\n",
      "current val acc: 0.5056008146639511\n",
      "current val acc: 0.35692464358452136\n",
      "current val acc: 0.6195264765784114\n",
      "current val acc: 0.4595213849287169\n",
      "current val acc: 0.39231160896130346\n",
      "current val acc: 0.5737016293279023\n",
      "current val acc: 0.3895112016293279\n",
      "current val acc: 0.3471232179226069\n",
      "current val acc: 0.4363543788187373\n",
      "current val acc: 0.3757637474541752\n",
      "current val acc: 0.4325356415478615\n",
      "current val acc: 0.3468686354378819\n",
      "current val acc: 0.38785641547861505\n",
      "current val acc: 0.30817209775967414\n",
      "current val acc: 0.6578411405295316\n",
      "current val acc: 0.3369399185336049\n",
      "current val acc: 0.672479633401222\n",
      "current val acc: 0.38314663951120165\n",
      "current val acc: 0.5492617107942973\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fa9e9b2d0a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moutput_val_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mval_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_val_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbest_val_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cnn_best_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0ebc936c0398>\u001b[0m in \u001b[0;36mcompute_acc\u001b[0;34m(p, g)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0ebc936c0398>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(prediction)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=model.to(device)\n",
    "best_model=None\n",
    "best_val_acc=0\n",
    "for i in range(epochs):\n",
    "    random.shuffle(train_data)\n",
    "    for j in range(int(data_len/batch_size)):\n",
    "        input_x, input_y = make_batch(j, batch_size)\n",
    "        #input_x, input_y = make_batch(0,2) #overfit\n",
    "        input_x=Variable(torch.from_numpy(input_x).float().to(device))\n",
    "        input_y=Variable(torch.from_numpy(input_y).float().to(device))\n",
    "        optimizer.zero_grad()\n",
    "        output_y=model(input_x)\n",
    "        loss=compute_loss(input_y, output_y, 10, batch_size)\n",
    "        #loss=criterion(output_y, input_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if i%100==0: print(loss)\n",
    "    output_val_y=model(val_x)\n",
    "    val_acc=compute_acc(output_val_y, val_y)\n",
    "    if val_acc>best_val_acc:\n",
    "        best_model = torch.save(model.state_dict(), \"cnn_best_model.pt\")\n",
    "        best_val_acc = val_acc\n",
    "    print(\"current val acc:\", val_acc)\n",
    "'''\n",
    "#overfit\n",
    "input_x, input_y = make_batch(0,2)\n",
    "input_x=Variable(torch.from_numpy(input_x).float().to(device))\n",
    "input_y=Variable(torch.from_numpy(input_y).float().to(device))\n",
    "output_y=model(input_x)\n",
    "print(input_y)\n",
    "print(output_y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_acc(output_y, input_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_test(index=1000):\n",
    "    if index == 1000:\n",
    "        index=random.randint(0, val_size)\n",
    "    print(index)\n",
    "    test_x=np.zeros((1,3,880))\n",
    "    print(val_x.shape)\n",
    "    for i in range(val_len[index]):\n",
    "        test_x[0][0][i]=val_x[index][0][i]\n",
    "        test_x[0][1][i]=val_x[index][1][i]\n",
    "        test_x[0][2][i]=val_x[index][2][i]\n",
    "    test_x=Variable(torch.from_numpy(test_x).float().to(device))\n",
    "    test_y=model(test_x)\n",
    "    \n",
    "    output_y=[]\n",
    "    gt_y=[]\n",
    "    for i in range(val_len[index]):\n",
    "        if i==0:\n",
    "            output_y.append(0)\n",
    "            gt_y.append(0)\n",
    "            continue\n",
    "        if test_y[0][0][i]>0.5 and test_y[0][0][i]>test_y[0][0][i+1] and test_y[0][0][i]>test_y[0][0][i-1]:\n",
    "            output_y.append(1)\n",
    "        else:\n",
    "            output_y.append(0)\n",
    "        if val_y[index][0][i]>0.5 and val_y[index][0][i]>val_y[index][0][i+1] and val_y[index][0][i]>val_y[index][0][i-1]:\n",
    "            gt_y.append(1)\n",
    "        else:\n",
    "            gt_y.append(0)\n",
    "    print(output_y)\n",
    "    print(gt_y)\n",
    "    return test_y.detach().reshape(-1).cpu().numpy(), gt_y, output_y\n",
    "    \n",
    "print(generate_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnMusic().to(device)\n",
    "model.load_state_dict(torch.load(\"cnn_best_model.pt\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "def AUC(score, truth):\n",
    "    plot_list = []\n",
    "    for thre in range(100):\n",
    "        threshold = thre * 1.0 / 100\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        result = score\n",
    "        target = np.full_like(result, 1 - threshold)\n",
    "        result = (np.sign(np.subtract(result, target)) == 1).astype(int)\n",
    "        for loc, i in enumerate(result):\n",
    "            if int(truth[loc]) * int(i) == 1:\n",
    "                TP += 1\n",
    "            elif int(truth[loc]) == 0 and int(i) == 0:\n",
    "                TN += 1\n",
    "            elif int(truth[loc]) == 1 and int(i) == 0:\n",
    "                FN += 1\n",
    "            elif int(truth[loc]) == 0 and int(i) == 1:\n",
    "                FP += 1\n",
    "        TP_rate = TP * 1.0 / (TP + FN)\n",
    "        FP_rate = FP * 1.0 / (FP + TN)\n",
    "        \n",
    "        plot_list.append((FP_rate, TP_rate))\n",
    "    return plot_list\n",
    "\n",
    "\n",
    "def plot_AUC():\n",
    "    score, gt_y, _ = generate_test()\n",
    "\n",
    "    result = AUC(score[:len(gt_y)], gt_y)\n",
    "    xs = [x[0] for x in result]\n",
    "    ys = [x[1] for x in result]\n",
    "    plt.scatter(xs, ys)\n",
    "    plt.show()\n",
    "    \n",
    "plot_AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,output_y = generate_test(26)\n",
    "output = []\n",
    "output.append(np.array(output_y))\n",
    "f = open(\"sample_prediction.pkl\", \"wb\")\n",
    "pickle.dump(output, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_y)\n",
    "print(val_x.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
