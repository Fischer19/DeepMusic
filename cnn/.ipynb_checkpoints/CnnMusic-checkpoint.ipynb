{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "device = torch.device(2 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CnnMusic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnMusic, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 128, 3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(64, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(64, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.ConvTranspose1d(64, 64, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv6 = nn.Conv1d(128, 64, 3, padding=1)\n",
    "        self.upsample2 = nn.ConvTranspose1d(64, 64, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv7 = nn.Conv1d(128, 128, 3, padding=1)\n",
    "        self.upsample3 = nn.ConvTranspose1d(128, 128, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv8 = nn.Conv1d(256, 32, 3, padding=1)\n",
    "        self.upsample4 = nn.ConvTranspose1d(32, 32, 3, padding=1, output_padding=1, stride=2)\n",
    "        self.conv9 = nn.Conv1d(64, 1, 1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        skip1=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv2(x)\n",
    "        skip2=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv3(x)\n",
    "        skip3=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv4(x)\n",
    "        skip4=x\n",
    "        x=F.max_pool1d(x, 2)\n",
    "        x=self.conv5(x)\n",
    "        x=self.upsample1(x)\n",
    "        x=torch.cat((x,skip4), dim=1)\n",
    "        x=self.upsample2(self.conv6(x))\n",
    "        x=torch.cat((x,skip3), dim=1)\n",
    "        x=self.upsample3(self.conv7(x))\n",
    "        x=torch.cat((x,skip2), dim=1)\n",
    "        x=self.upsample4(self.conv8(x))\n",
    "        x=torch.cat((x,skip1), dim=1)\n",
    "        x=self.conv9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512])\n",
      "torch.Size([1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "model=CnnMusic()\n",
    "x=torch.from_numpy(np.random.randn(1,3,512)).float()\n",
    "print(x.shape)\n",
    "y=model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373\n",
      "1373\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/yiqin/2018summer_project/data/smooth_data_long.pkl\", \"rb\") as f:\n",
    "    dic = pickle.load(f)\n",
    "    train_X = dic[\"X\"]\n",
    "    train_Y = dic[\"Y\"]\n",
    "print(len(train_X))\n",
    "print(len(train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "for i, x in enumerate(train_X):\n",
    "    temp=[]\n",
    "    temp.append(train_X[i])\n",
    "    temp.append(train_Y[i])\n",
    "    data.append(temp)\n",
    "import random\n",
    "#random.shuffle(data)\n",
    "print(len(data))\n",
    "train_data=data[:1300]\n",
    "val_data=data[1300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size=len(val_data)\n",
    "val_x=np.zeros((val_size,3,880))\n",
    "val_y=np.zeros((val_size,1,880))\n",
    "val_len=[]\n",
    "for i in range(val_size):\n",
    "    val_len.append(len(val_data[i][0]))\n",
    "    l=len(val_data[i][0])\n",
    "    for j in range(880):\n",
    "        val_x[i][0][j]=val_data[i][0][j%l][1]-val_data[i][0][j%l][0]\n",
    "        val_x[i][1][j]=val_data[i][0][j%l][2]\n",
    "        if (j%l)!=l-1:\n",
    "            val_x[i][2][j]=val_data[i][0][(j+1)%l][0]-val_data[i][0][j%l][1]\n",
    "        else:\n",
    "            val_x[i][2][j]=random.random()\n",
    "        val_y[i][0][j]=val_data[i][1][j%l]\n",
    "#print(val_x)\n",
    "#print(val_y)\n",
    "val_x=Variable(torch.from_numpy(val_x).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(prediction, s):\n",
    "    output=[]\n",
    "    for i in range(s):\n",
    "        temp=[]\n",
    "        for j in range(val_len[i]):\n",
    "            if j==0:\n",
    "                temp.append(0)\n",
    "                continue\n",
    "            if prediction[i][0][j]>0.5 and prediction[i][0][j]>prediction[i][0][j+1] and prediction[i][0][j]>prediction[i][0][j-1]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        output.append(temp)\n",
    "    return output\n",
    "\n",
    "def compute_acc(p, g, s):\n",
    "    p=decode(p, s)\n",
    "    g=decode(g, s)\n",
    "    cor=0\n",
    "    total=0\n",
    "    for i in range(s):\n",
    "        for j in range(val_len[i]):\n",
    "            if g[i][j] == 1: total+=1\n",
    "            if p[i][j]*g[i][j] == 1: cor+=1\n",
    "            #if p[i][j]==g[i][j]: cor+=1\n",
    "            #total+=1\n",
    "    acc=float(cor)/float(total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_batch(index, batch_size):\n",
    "    s=index*batch_size\n",
    "    xin=np.zeros((batch_size,3,880))\n",
    "    yin=np.zeros((batch_size,1,880))\n",
    "    for i in range(batch_size):\n",
    "        l=len(train_data[s+i][0])\n",
    "        for j in range(880):\n",
    "            xin[i][0][j]=train_data[s+i][0][j%l][1]-train_data[s+i][0][j%l][0]\n",
    "            xin[i][1][j]=train_data[s+i][0][j%l][2]\n",
    "            if (j%l)!=l-1:\n",
    "                xin[i][2][j]=train_data[s+i][0][(j+1)%l][0]-train_data[s+i][0][j%l][1]\n",
    "            else:\n",
    "                xin[i][2][j]=random.random()\n",
    "            yin[i][0][j]=train_data[s+i][1][j%l]\n",
    "    return xin, yin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=CnnMusic()\n",
    "lr=1e-3\n",
    "decay=5e-8\n",
    "optimizer=optim.Adam(model.parameters(),\n",
    "                     lr=lr,\n",
    "                     weight_decay=decay)\n",
    "batch_size=100\n",
    "epochs=100\n",
    "loss=0\n",
    "data_len=len(train_data)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(gy,y,ratio):\n",
    "    temp=gy.cpu().numpy()\n",
    "    mask=np.ones_like(temp)\n",
    "    mask[gy>0.99]=ratio\n",
    "    mask=torch.from_numpy(mask).to(device)\n",
    "    loss=torch.sub(gy,y)\n",
    "    loss=torch.mul(loss, loss)\n",
    "    loss=torch.mul(loss, mask)\n",
    "    loss=torch.sum(loss)\n",
    "    loss/=880\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7312, device='cuda:2')\n",
      "current val acc: 0.689312437181253\n",
      "tensor(0.1759, device='cuda:2')\n",
      "current val acc: 0.6486245021032647\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d6112da95f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_len\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#input_x, input_y = make_batch(0,1) #overfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minput_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e829966433e5>\u001b[0m in \u001b[0;36mmake_batch\u001b[0;34m(index, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m880\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mxin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mxin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mxin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=model.to(device)\n",
    "best_model=None\n",
    "best_val_acc=0\n",
    "for i in range(epochs):\n",
    "    random.shuffle(train_data)\n",
    "    for j in range(int(data_len/batch_size)):\n",
    "        input_x, input_y = make_batch(j, batch_size)\n",
    "        #input_x, input_y = make_batch(0,1) #overfit\n",
    "        input_x=Variable(torch.from_numpy(input_x).float().to(device))\n",
    "        input_y=Variable(torch.from_numpy(input_y).float().to(device))\n",
    "        optimizer.zero_grad()\n",
    "        output_y=model(input_x)\n",
    "        loss=compute_loss(input_y, output_y, 2)\n",
    "        #loss=criterion(output_y, input_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    output_val_y=model(val_x)\n",
    "    val_acc=compute_acc(output_val_y, val_y, val_size)\n",
    "    if val_acc>best_val_acc:\n",
    "        best_model = torch.save(model.state_dict(), \"cnn_best_model.pt\")\n",
    "        best_val_acc = val_acc\n",
    "    print(\"current val acc:\", val_acc)\n",
    "'''\n",
    "#overfit\n",
    "input_x, input_y = make_batch(0,1)\n",
    "input_x=Variable(torch.from_numpy(input_x).float().to(device))\n",
    "input_y=Variable(torch.from_numpy(input_y).float().to(device))\n",
    "output_y=model(input_x)\n",
    "print(input_y)\n",
    "print(output_y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_test(index=1000):\n",
    "    if index == 1000:\n",
    "        index=random.randint(0, val_size)\n",
    "    print(index)\n",
    "    test_x=np.zeros((1,3,880))\n",
    "    print(val_x.shape)\n",
    "    for i in range(val_len[index]):\n",
    "        test_x[0][0][i]=val_x[index][0][i]\n",
    "        test_x[0][1][i]=val_x[index][1][i]\n",
    "        test_x[0][2][i]=val_x[index][2][i]\n",
    "    test_x=Variable(torch.from_numpy(test_x).float().to(device))\n",
    "    test_y=model(test_x)\n",
    "    \n",
    "    output_y=[]\n",
    "    gt_y=[]\n",
    "    for i in range(val_len[index]):\n",
    "        if i==0:\n",
    "            output_y.append(0)\n",
    "            gt_y.append(0)\n",
    "            continue\n",
    "        if test_y[0][0][i]>0.5 and test_y[0][0][i]>test_y[0][0][i+1] and test_y[0][0][i]>test_y[0][0][i-1]:\n",
    "            output_y.append(1)\n",
    "        else:\n",
    "            output_y.append(0)\n",
    "        if val_y[index][0][i]>0.5 and val_y[index][0][i]>val_y[index][0][i+1] and val_y[index][0][i]>val_y[index][0][i-1]:\n",
    "            gt_y.append(1)\n",
    "        else:\n",
    "            gt_y.append(0)\n",
    "    print(output_y)\n",
    "    print(gt_y)\n",
    "    return test_y.detach().reshape(-1).cpu().numpy(), gt_y, output_y\n",
    "    \n",
    "print(generate_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnMusic().to(device)\n",
    "model.load_state_dict(torch.load(\"cnn_best_model.pt\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "def AUC(score, truth):\n",
    "    plot_list = []\n",
    "    for thre in range(100):\n",
    "        threshold = thre * 1.0 / 100\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        result = score\n",
    "        target = np.full_like(result, 1 - threshold)\n",
    "        result = (np.sign(np.subtract(result, target)) == 1).astype(int)\n",
    "        for loc, i in enumerate(result):\n",
    "            if int(truth[loc]) * int(i) == 1:\n",
    "                TP += 1\n",
    "            elif int(truth[loc]) == 0 and int(i) == 0:\n",
    "                TN += 1\n",
    "            elif int(truth[loc]) == 1 and int(i) == 0:\n",
    "                FN += 1\n",
    "            elif int(truth[loc]) == 0 and int(i) == 1:\n",
    "                FP += 1\n",
    "        TP_rate = TP * 1.0 / (TP + FN)\n",
    "        FP_rate = FP * 1.0 / (FP + TN)\n",
    "        \n",
    "        plot_list.append((FP_rate, TP_rate))\n",
    "    return plot_list\n",
    "\n",
    "\n",
    "def plot_AUC():\n",
    "    score, gt_y, _ = generate_test()\n",
    "\n",
    "    result = AUC(score[:len(gt_y)], gt_y)\n",
    "    xs = [x[0] for x in result]\n",
    "    ys = [x[1] for x in result]\n",
    "    plt.scatter(xs, ys)\n",
    "    plt.show()\n",
    "    \n",
    "plot_AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,output_y = generate_test(26)\n",
    "output = []\n",
    "output.append(np.array(output_y))\n",
    "f = open(\"sample_prediction.pkl\", \"wb\")\n",
    "pickle.dump(output, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_y)\n",
    "print(val_x.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
