{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nNOTE: \\nEncoder RNN input of size (Sentence_length * input_feature)\\nEncoder RNN output of size (1 * 1 * hidden_size)  should be (num_sentences * 1 * hidden_size)\\n\\nDecoder RNN input of size 0 (scalar value)\\nDecoder RNN output of size (1 * target_num)   should be (num_sentences * target_num)\\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "MAX_LENGTH = 865\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.embedding = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input.float()).view(1, 1,-1)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.lstm_1 = nn.LSTM(self.output_size, self.hidden_size)\n",
    "        self.lstm_2 = nn.LSTM(self.output_size, self.hidden_size)\n",
    "        self.lstm_3 = nn.LSTM(self.output_size, self.hidden_size)\n",
    "        self.lstm_4 = nn.LSTM(self.output_size, self.hidden_size)\n",
    "        self.lstm_5 = nn.LSTM(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, ch_1, ch_2, ch_3, ch_4, ch_5):\n",
    "        (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3), (hidden_4, cell_4), (hidden_5, cell_5) = ch_1, ch_2, ch_3, ch_4, ch_5\n",
    "    \n",
    "        output, (hidden_1, cell_1) = self.lstm_1(input.view(1,1,-1).float(), (hidden_1, cell_1))\n",
    "        output = self.out(output)\n",
    "        output_1 = output\n",
    "        output, (hidden_2, cell_2) = self.lstm_2(output, (hidden_2, cell_2))\n",
    "        output = self.out(output)\n",
    "        output_2 = output\n",
    "        output, (hidden_3, cell_3) = self.lstm_3(output + output_1, (hidden_3, cell_3)) # skip_connection 1\n",
    "        output = self.out(output)\n",
    "        output_3 = output\n",
    "        output, (hidden_4, cell_4) = self.lstm_4(output + output_2, (hidden_4, cell_4)) # skip_connection 2\n",
    "        output = self.out(output)\n",
    "        output_4 = output\n",
    "        output, (hidden_5, cell_5) = self.lstm_5(output + output_3, (hidden_5, cell_5)) # skip_connection 3\n",
    "        output = self.out(output[0])\n",
    "        output = self.softmax(output)\n",
    "        return output, (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3),  (hidden_4, cell_4), (hidden_5, cell_5)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    def init_cell(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "NOTE: \n",
    "Encoder RNN input of size (Sentence_length * input_feature)\n",
    "Encoder RNN output of size (1 * 1 * hidden_size)  should be (num_sentences * 1 * hidden_size)\n",
    "\n",
    "Decoder RNN input of size 0 (scalar value)\n",
    "Decoder RNN output of size (1 * target_num)   should be (num_sentences * target_num)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# load data from file\n",
    "with open(\"pitch_data.pkl\", \"rb\") as f:\n",
    "    dic = pickle.load(f)\n",
    "    train_X = dic[\"X\"]\n",
    "    train_Y = dic[\"Y\"]\n",
    "    time_X = dic[\"time\"]\n",
    "    \n",
    "for i in range(train_Y.shape[0]):\n",
    "    train_Y[i] = torch.from_numpy((train_Y[i] == 4).astype(int)).float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_transform(train_x, time_x, i):\n",
    "    output = torch.from_numpy(np.array([train_x[i], time_x[i]]))\n",
    "    return output.transpose(1, 0).to(device)\n",
    "\n",
    "def input_factorize(train_x):\n",
    "    output = []\n",
    "    for i in range(train_x.shape[0]):\n",
    "        for item in np.array_split(train_x[i], train_x[i].shape[0] / 9):\n",
    "            output.append(item)\n",
    "    return output\n",
    "\n",
    "\n",
    "def target_factorize(train_y):\n",
    "    output = []\n",
    "    for i in range(train_y.shape[0]):\n",
    "        for item in np.array_split(train_y[i].numpy(), train_y[i].shape[0] / 9):\n",
    "            output.append(torch.Tensor(item))\n",
    "    return output\n",
    "\n",
    "def target_transform(train_y):\n",
    "    output = torch.zeros((1, 2))\n",
    "    output[0, int(train_y)] = 1\n",
    "    return output.unsqueeze(1).to(device)\n",
    "\n",
    "\n",
    "\n",
    "train_X = input_factorize(train_X)\n",
    "time_X = input_factorize(time_X)\n",
    "target_Tensor = target_factorize(train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51954\n",
      "tensor([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))\n",
    "print(target_Tensor[50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "teacher_forcing_ratio = 1\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, decoder, decoder_optimizer, criterion, verbose = False):\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "        \n",
    "    hidden_1 = decoder.init_hidden()\n",
    "    hidden_2 = decoder.init_hidden()\n",
    "    hidden_3 = decoder.init_hidden()\n",
    "    hidden_4 = decoder.init_hidden()\n",
    "    hidden_5 = decoder.init_hidden()\n",
    "    cell_1 = decoder.init_cell()\n",
    "    cell_2 = decoder.init_cell()\n",
    "    cell_3 = decoder.init_cell()\n",
    "    cell_4 = decoder.init_cell()\n",
    "    cell_5 = decoder.init_cell()\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    decoder_input = input_tensor[0]\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3),  (hidden_4, cell_4), (hidden_5, cell_5) = decoder(decoder_input, \n",
    "                            (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3),  (hidden_4, cell_4), (hidden_5, cell_5))\n",
    "            if verbose:\n",
    "                temp.append(int(torch.argmax(decoder_output, dim = 1).cpu().numpy()))\n",
    "            #print(di, input_tensor.shape)\n",
    "            #print(input_tensor[di])\n",
    "            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0).long())\n",
    "            decoder_input = input_tensor[di]\n",
    "            \"\"\"\n",
    "            if di == 0:\n",
    "                print(\"decoder input shape:\", decoder_input.shape)\n",
    "                print(\"decoder output shape:\", decoder_output.shape)\n",
    "            \"\"\"\n",
    "    else:\n",
    "        for di in range(1, input_length):\n",
    "            decoder_output, (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3),  (hidden_4, cell_4), (hidden_5, cell_5) = decoder(decoder_input, \n",
    "                            (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3),  (hidden_4, cell_4), (hidden_5, cell_5))\n",
    "            if verbose:\n",
    "                temp.append(int(torch.argmax(decoder_output, dim = 1).cpu().numpy()))\n",
    "            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "            \n",
    "            #print(loss)\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "    loss.backward()\n",
    "    if verbose:\n",
    "        print(\"Prediction :\", temp) \n",
    "        print(\"Target:\", target_tensor) \n",
    "    \n",
    "\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(decoder, n_iters, print_every = 1000, plot_every = 100, learning_rate = 0.01, CEL_weight=[1,5]):    \n",
    "    start = time.time()\n",
    "    \n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate, weight_decay = 0.95)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight = torch.Tensor(CEL_weight).to(device))\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        num = iter % 51954\n",
    "        verbose = (iter % print_every == 0)\n",
    "        input_tensor = input_transform(train_X, time_X, num - 1).to(device)\n",
    "        target_tensor = target_Tensor[num].to(device)\n",
    "        #print(input_tensor.shape)\n",
    "        #print(target_tensor.shape)\n",
    "        if input_tensor.shape[0] != target_tensor.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, decoder, \n",
    "                     decoder_optimizer, criterion, verbose = verbose)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "0m 5s (- 9m 33s) (100 1%) 0.5730\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "0m 17s (- 9m 26s) (300 3%) 1.0474\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.], device='cuda:0')\n",
      "0m 23s (- 9m 20s) (400 4%) 0.4786\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "0m 29s (- 9m 13s) (500 5%) 0.4626\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "0m 34s (- 9m 5s) (600 6%) 0.4382\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.], device='cuda:0')\n",
      "0m 44s (- 8m 34s) (800 8%) 0.8720\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.], device='cuda:0')\n",
      "0m 49s (- 8m 24s) (900 9%) 0.4493\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "0m 54s (- 8m 11s) (1000 10%) 0.4343\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "0m 59s (- 8m 1s) (1100 11%) 0.4482\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.], device='cuda:0')\n",
      "1m 4s (- 7m 53s) (1200 12%) 0.4299\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.], device='cuda:0')\n",
      "1m 9s (- 7m 46s) (1300 13%) 0.4364\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.], device='cuda:0')\n",
      "1m 15s (- 7m 43s) (1400 14%) 0.4246\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.], device='cuda:0')\n",
      "1m 20s (- 7m 35s) (1500 15%) 0.4216\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "1m 25s (- 7m 27s) (1600 16%) 0.4451\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], device='cuda:0')\n",
      "1m 30s (- 7m 20s) (1700 17%) 0.4269\n",
      "Prediction : [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Target: tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.], device='cuda:0')\n",
      "1m 35s (- 7m 12s) (1800 18%) 0.4283\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-4cd217aa18a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCEL_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-182-8e4281d23a25>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(decoder, n_iters, print_every, plot_every, learning_rate, CEL_weight)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         loss = train(input_tensor, target_tensor, decoder, \n\u001b[0;32m---> 23\u001b[0;31m                      decoder_optimizer, criterion, verbose = verbose)\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-e1a420bb1765>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, decoder, decoder_optimizer, criterion, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             decoder_output, (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3),  (hidden_4, cell_4), (hidden_5, cell_5) = decoder(decoder_input, \n\u001b[0;32m---> 33\u001b[0;31m                             (hidden_1, cell_1), (hidden_2, cell_2), (hidden_3, cell_3),  (hidden_4, cell_4), (hidden_5, cell_5))\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-8c00566b58d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, ch_1, ch_2, ch_3, ch_4, ch_5)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# skip_connection 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mhidden_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 256\n",
    "output_size = 2\n",
    "\n",
    "decoder = DecoderRNN(hidden_size, output_size).to(device)\n",
    "\n",
    "trainIters(decoder, 10000, print_every=100, learning_rate=1e-3, CEL_weight = [0.1,0.9])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51954\n",
      "51954\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
