{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# naive LSTM model trained with smooth data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(2 if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, augmented_size, hidden_size, output_size, batch_size = 1, batch_length = 100, dropout_p = 0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.augmented_size = augmented_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_length = batch_length\n",
    "        self.verbose = (self.dropout_p != 0)\n",
    "\n",
    "        self.cnn1 = nn.Conv1d(self.input_size, self.augmented_size//2 , kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.cnn2 = nn.Conv1d(self.augmented_size//2, self.augmented_size, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.lstm_1 = nn.LSTM(self.augmented_size, self.hidden_size//2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_2 = nn.LSTM(self.hidden_size, self.hidden_size//2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_3 = nn.LSTM(self.hidden_size, self.hidden_size//2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_4 = nn.LSTM(self.hidden_size, self.hidden_size//2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_5 = nn.LSTM(self.hidden_size, self.hidden_size//2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_6 = nn.LSTM(self.hidden_size, self.hidden_size//2, num_layers=1, bidirectional=True)\n",
    "        self.lstm_7 = nn.LSTM(self.hidden_size, self.hidden_size//2, num_layers=1, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(self.dropout_p)\n",
    "        self.dropout2 = nn.Dropout(self.dropout_p)\n",
    "        self.dropout3 = nn.Dropout(self.dropout_p)\n",
    "        self.dropout4 = nn.Dropout(self.dropout_p)\n",
    "        self.dropout5 = nn.Dropout(self.dropout_p)\n",
    "        self.dropout6 = nn.Dropout(self.dropout_p)\n",
    "        # map the output of LSTM to the output space\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.hidden1 = self.init_hidden()\n",
    "        self.hidden2 = self.init_hidden()\n",
    "        self.hidden3 = self.init_hidden()\n",
    "        self.hidden4 = self.init_hidden()\n",
    "        self.hidden5 = self.init_hidden()\n",
    "        self.hidden6 = self.init_hidden()\n",
    "        self.hidden7 = self.init_hidden()\n",
    "\n",
    "        output = self.cnn1(input.view(-1,3,1))\n",
    "        output = self.relu1(output)\n",
    "        output = self.cnn2(output)\n",
    "        output = self.relu2(output)\n",
    "\n",
    "        output, self.hidden1 = self.lstm_1(output.view(-1,1,self.augmented_size), self.hidden1)\n",
    "        if self.verbose:\n",
    "            output = self.dropout1(output)\n",
    "        output_1 = output\n",
    "\n",
    "        output, self.hidden2 = self.lstm_2(output, self.hidden2)\n",
    "        if self.verbose:\n",
    "            output = self.dropout2(output)\n",
    "        output_2 = output\n",
    "\n",
    "        output, self.hidden3 = self.lstm_3(output + output_1, self.hidden3)  # skip_connection 1\n",
    "        if self.verbose:\n",
    "            output = self.dropout3(output)\n",
    "        output_3 = output\n",
    "\n",
    "        output, self.hidden4 = self.lstm_4(output + output_2, self.hidden4)  # skip_connection 2\n",
    "        if self.verbose:\n",
    "            output = self.dropout4(output)\n",
    "        output_4 = output\n",
    "\n",
    "        output, self.hidden5 = self.lstm_5(output + output_3, self.hidden5)  # skip_connection 3\n",
    "        if self.verbose:\n",
    "            output = self.dropout5(output)\n",
    "        output_5 = output\n",
    "\n",
    "        output, self.hidden6 = self.lstm_6(output + output_4, self.hidden6)  # skip_connection 4\n",
    "        if self.verbose:\n",
    "            output = self.dropout6(output)\n",
    "        output, self.hidden7 = self.lstm_7(output + output_5, self.hidden7)  # skip_connection 5\n",
    "        \n",
    "        output = self.out(output).view(self.batch_size, self.batch_length,1)\n",
    "        # output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_size // 2, device=device),\n",
    "                torch.randn(2, 1, self.hidden_size // 2, device=device))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "def validate(decoder, val_x, val_y, val_threshold = 0.5):\n",
    "\n",
    "    count = 0\n",
    "    total = 0\n",
    "    total_1 = 0\n",
    "    \n",
    "    val_set = data_utils.TensorDataset(val_x, val_y)\n",
    "    val_loader=data_utils.DataLoader(dataset=val_set, batch_size=BATCH_SIZE, drop_last=True, shuffle=True) \n",
    "\n",
    "    \n",
    "    for i, (val_x, val_y) in enumerate(val_loader):\n",
    "        X = val_x.to(device).float()\n",
    "        result = decoder(X).squeeze().cpu().detach().numpy()\n",
    "        Y = val_y.squeeze().numpy()\n",
    "        gt = (Y == 1).astype(int)\n",
    "        pr = (result > 0.5).astype(int)\n",
    "        count += np.sum(gt * pr)\n",
    "        total += np.sum(gt)\n",
    "        total_1 += np.sum(pr)\n",
    "    score = (count / total) + (count / total_1)\n",
    "    acc = str('%.4f'%((count / total * 100)) + \"%\")\n",
    "    if total_1 == 0.0:\n",
    "        one_acc = str('%.4f'%(0) + \"%\")\n",
    "    else:\n",
    "        one_acc = str('%.4f'%((count / total_1 * 100)) + \"%\")\n",
    "    return acc, one_acc, score\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def penalty_loss(penalty, criterion, output, target):\n",
    "    loss = 0\n",
    "    batch_size = target.shape[0]\n",
    "    for j in range(target.shape[0]):\n",
    "        for i in range(target.shape[0]):\n",
    "            if int(target[j, i]) == 1:\n",
    "                loss += penalty[0] * criterion(output[j, i], target[j, i])\n",
    "            else:\n",
    "                loss += penalty[1] * criterion(output[j, i], target[j, i])\n",
    "    return loss/batch_size\n",
    "\n",
    "def train(input_tensor, target_tensor, decoder, decoder_optimizer, criterion, penalty = (1, 0.5)):\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    decoder_output= decoder(input_tensor)\n",
    "    \n",
    "    #if verbose:\n",
    "    #    print(\"prediction score:\", decoder_output.squeeze().detach().cpu().numpy())\n",
    "    #    print(\"ground truch:\", target_tensor.squeeze().cpu().numpy())\n",
    "\n",
    "    loss += penalty_loss(penalty, criterion, decoder_output.squeeze(0), target_tensor.float())\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def factorize(data_X, data_Y, flag, batch_size, batch_length):\n",
    "    if flag:\n",
    "        new_X = []\n",
    "        new_Y = []\n",
    "        for i in range(len(data_X)):\n",
    "            X, Y = data_X[i], data_Y[i]\n",
    "            flag = []\n",
    "            for loc, j in enumerate(Y):\n",
    "                if j == 1:\n",
    "                    flag.append(loc)\n",
    "            prev = 0\n",
    "            for j in range(4, len(flag), 5):\n",
    "                new_X.append(pad(torch.from_numpy(X[prev:flag[j]]), batch_length))\n",
    "                new_Y.append(pad(torch.from_numpy(Y[prev:flag[j]]), batch_length))\n",
    "                prev = flag[j]\n",
    "        batch_X = []\n",
    "        batch_Y = []\n",
    "        \"\"\"for i in range(0, len(new_X), batch_size):\n",
    "            if (i + batch_size) > (len(new_X) - 1):\n",
    "                break\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            for j in range(batch_size):\n",
    "                batch_x.append(pad(new_X[i + j], batch_length))\n",
    "                batch_y.append(pad(new_Y[i + j], batch_length))\n",
    "            batch_X.append(torch.stack(batch_x))\n",
    "            batch_Y.append(torch.stack(batch_y))\n",
    "        return batch_X, batch_Y\"\"\"\n",
    "        return torch.stack(new_X), torch.stack(new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "class CrossValidator:\n",
    "    def __init__(self, model, partition=5, decoder=None, batch_size=BATCH_SIZE, batch_length = 100, epochs=10, lr=1e-2, \n",
    "                 augment_data=True, print_every = 1000, plot_every = 100, gamma = 0.1):\n",
    "        self.model=model\n",
    "        self.data_X = []\n",
    "        self.data_Y = []\n",
    "        with open(\"/home/yiqin/2018summer_project/data/smooth_3d1s_augmented.pkl\", \"rb\") as f:\n",
    "            data= pickle.load(f)\n",
    "            for i in range(len(data)):\n",
    "                self.data_X.append(data[i][0])\n",
    "                self.data_Y.append(data[i][1])\n",
    "        self.data_size = len(data)\n",
    "        self.partition=partition\n",
    "        self.decoder=decoder\n",
    "        self.train_X=[]\n",
    "        self.train_Y=[]\n",
    "        self.val_X=[]\n",
    "        self.val_Y=[]\n",
    "        self.precision_history=[]\n",
    "        self.recall_history=[]\n",
    "        self.loss_history=[]\n",
    "        self.best_acc = 0\n",
    "        self.batch_size=batch_size\n",
    "        self.batch_length=batch_length\n",
    "        self.epochs=epochs\n",
    "        self.lr=lr\n",
    "        self.augment_data_flag=augment_data\n",
    "        self.gamma = gamma\n",
    "        self.print_every = print_every\n",
    "        self.plot_every = plot_every\n",
    "        \n",
    "        \n",
    "    def create_data(self, part):\n",
    "        train_X=[]\n",
    "        train_Y=[]\n",
    "        val_X=[]\n",
    "        val_Y=[]\n",
    "        cut=int(self.data_size/self.partition)\n",
    "        for i in range(self.data_size):\n",
    "            if i<cut*part or i>=cut*(part+1):\n",
    "                train_X.append(np.array(self.data_X[i]))\n",
    "                train_Y.append(np.array(self.data_Y[i]))\n",
    "            else:\n",
    "                val_X.append(np.array(self.data_X[i]))\n",
    "                val_Y.append(np.array(self.data_Y[i]))\n",
    "        return train_X, train_Y, val_X, val_Y\n",
    "    \n",
    "    def tensorize(self, p):\n",
    "        p=np.array(p)\n",
    "        p=torch.from_numpy(p).float()\n",
    "        p=p.to(device)\n",
    "        return p\n",
    "    \n",
    "    def asMinutes(self, s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "    def timeSince(self,since, percent):\n",
    "        now = time.time()\n",
    "        s = now - since\n",
    "        es = s / (percent)\n",
    "        rs = es - s\n",
    "        return '%s (- %s)' % (self.asMinutes(s), self.asMinutes(rs))\n",
    "\n",
    "    def compute(self):\n",
    "        for i in range(self.partition):\n",
    "            start = time.time()\n",
    "            temptrain_X, temptrain_Y, tempval_X, tempval_Y = self.create_data(i)\n",
    "            self.train_X, self.train_Y = factorize(temptrain_X, temptrain_Y, self.augment_data_flag, self.batch_size, self.batch_length)\n",
    "            self.val_X, self.val_Y = factorize(tempval_X, tempval_Y, self.augment_data_flag, self.batch_size, self.batch_length)\n",
    "            train_set = data_utils.TensorDataset(self.train_X, self.train_Y)\n",
    "            train_loader=data_utils.DataLoader(dataset=train_set, batch_size=BATCH_SIZE, drop_last=True, shuffle=True) \n",
    "            print(train_loader)\n",
    "            \n",
    "            print(i, \"phase 1 completed.\")\n",
    "            \n",
    "            cur_model = deepcopy(self.model).to(device)\n",
    "            \n",
    "            optimizer = optim.SGD(cur_model.parameters(), lr = self.lr, weight_decay = 1e-5)\n",
    "    \n",
    "            criterion = nn.SmoothL1Loss()\n",
    "\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = self.gamma)\n",
    "\n",
    "            print_loss_total = 0\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "            \n",
    "            for j in range(self.epochs):\n",
    "                for num, (train_X, train_Y)in enumerate(train_loader):\n",
    "                    input_tensor = train_X.to(device).float()\n",
    "                    target_tensor = train_Y.to(device).float()\n",
    "                    print(input_tensor.shape)\n",
    "                    loss = train(input_tensor, target_tensor, cur_model, decoder_optimizer=optimizer, criterion= criterion)\n",
    "                    print(loss)\n",
    "                    print_loss_total += loss\n",
    "                    plot_loss_total += loss\n",
    "                    \n",
    "                    if num%self.plot_every == 0:\n",
    "                        plot_loss_avg = plot_loss_total / self.plot_every\n",
    "                        plot_loss_total = 0\n",
    "                        self.loss_history.append(plot_loss_avg)\n",
    "\n",
    "                    if num % self.print_every == 0:\n",
    "                        acc, one_acc, score = validate(cur_model, self.val_X, self.val_Y)\n",
    "                        self.precision_history.append(acc[:-1])\n",
    "                        self.recall_history.append(one_acc[:-1])\n",
    "                        print_loss_avg = print_loss_total / self.print_every\n",
    "                        print_loss_total = 0\n",
    "                        print(\"epoch %i\"%j)\n",
    "                        p = self.timeSince(start, (num+j*len(self.train_X)) / (self.epochs * len(self.train_X)))\n",
    "                        print('%s (%d %d%%) %.4f' % (p, num, num / (self.epochs * len(self.train_X)) * self.print_every,\n",
    "                                                     print_loss_avg))\n",
    "                        print(\"validation accuracy:\", acc)\n",
    "                        print(\"validation prediction accuracy:\", one_acc)\n",
    "                        if(score > self.best_acc):\n",
    "                        #    torch.save(cur_model.state_dict(), '/home/yiqin/2018summer_project/saved_model/Bi-LSTM-CNN_best(cv).pt')\n",
    "                            self.best_acc = score\n",
    "                        print(\"best_score:\", self.best_acc)\n",
    "\n",
    "                scheduler.step()\n",
    "                #torch.save(cur_model.state_dict(), '/home/yiqin/2018summer_project/saved_model/Bi-LSTM-CNN(cv){}-{}.pt'.format(i,j))\n",
    "                \n",
    "        return self.loss_history, self.precision_history, self.recall_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 phase 1 completed.\n",
      "torch.Size([40, 100, 3])\n",
      "3.499295949935913\n",
      "torch.Size([40, 100, 3])\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "torch.Size([40, 100, 3])\n",
      "[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "torch.Size([40, 100, 3])\n",
      "[1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "torch.Size([40, 100, 3])\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "torch.Size([40, 100, 3])\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "torch.Size([40, 100, 3])\n",
      "[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "torch.Size([40, 100, 3])\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "torch.Size([40, 100, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-60c9efd0853d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossValidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-05bfc9801b66>\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-32fb0039118d>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(decoder, val_x, val_y, val_threshold)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8e60b2f68b91>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0moutput_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# skip_connection 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "augmented_size = 32\n",
    "hidden_size = 256\n",
    "output_size = 1\n",
    "batch_size = 40\n",
    "batch_length = 100\n",
    "model = DecoderRNN(input_size, augmented_size, hidden_size, output_size, batch_size, batch_length, dropout_p = 0).to(device)\n",
    "cv = CrossValidator(model, partition=5, epochs=5, batch_size = batch_size)\n",
    "losses, precision, recall = cv.compute()\n",
    "\n",
    "\n",
    "dic = {}\n",
    "dic[\"loss\"] = losses\n",
    "dic[\"precision\"] = precision\n",
    "dic[\"recall\"] = recall\n",
    "\n",
    "#f = open(\"/home/yiqin/2018summer_project/saved_model/Bi-LSTM-CNN_losses(cv-l2).pkl\", \"wb\")\n",
    "#pickle.dump(dic, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_x):\n",
    "    prediction = []\n",
    "    for i in range(len(val_x)):\n",
    "        X = val_x[i].to(device).float()\n",
    "        result = model(X).squeeze().cpu().detach().numpy()\n",
    "        pr = []\n",
    "        pr.append(1)\n",
    "        for j in range(1, len(result) - 1):\n",
    "            if result[j] > 0.5 and result[j] > result[j-1] and result[j] > result[j+1]:\n",
    "                pr.append(1)\n",
    "            else:\n",
    "                pr.append(0)\n",
    "        pr.append(0)\n",
    "        prediction.append(np.array(pr))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "augmented_size = 32\n",
    "hidden_size = 256\n",
    "output_size = 1\n",
    "model = DecoderRNN(input_size, augmented_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(torch.load(\"/home/yiqin/2018summer_project/saved_model/HallofFame/Bi-LSTM-CNN1.pt\"))\n",
    "prediction = evaluate(model, val_X)\n",
    "acc, one_acc = validate(model, val_X,val_Y, 0.52)\n",
    "print(acc, one_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"/home/yiqin/2018summer_project/prediction/BiLSTM-CNN.pkl\", \"wb\")\n",
    "pickle.dump(prediction, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad(vector, pad, dim=0):\n",
    "    pad_size=list(vector.shape)\n",
    "    #print(pad_size)\n",
    "    pad_size[dim]=pad-vector.size(dim)\n",
    "    #print(pad_size[dim])\n",
    "    if pad_size[dim]<0:\n",
    "        print(\"FATAL ERROR: pad_size=100 not enough!\")\n",
    "    return torch.cat([vector, torch.zeros(*pad_size).type(vector.type())], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "a = torch.from_numpy(a)\n",
    "b = np.array([2,3,4,5,6])\n",
    "b = torch.from_numpy(b)\n",
    "c = []\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "print(torch.stack(c).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
